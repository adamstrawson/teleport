---
title: Dynamic Kubernetes Cluster Registration
description: Register and unregister Kubernetes clusters without restarting a Teleport Kubernetes Service instance.
---

Dynamic Kubernetes cluster registration enables you to manage the Kubernetes
clusters connected to your Teleport cluster without needing to modify the
configuration file of an individual Kubernetes Service instance. This is well
suited for situations in which you have deployed multiple Kubernetes Service
instances or needto add and remove access to Kubernetes clusters regularly. 

## Prerequisites

(!docs/pages/includes/edition-prereqs-tabs.mdx!)

- A Linux host where you will install the Teleport Kubernetes Service.

  <Notice type="tip">

  Our `teleport-kube-agent` Helm chart does not support dynamic Kubernetes
  cluster registration.

  </Notice>

- A Kubernetes cluster to join to your Teleport cluster. 

(!docs/pages/includes/tctl.mdx!)

## Step 1/3. Set up the Teleport Kubernetes Service

### Get a join token

Establish trust between your Kubernetes Service instance and your Teleport
cluster by creating a join token for the Kubernetes Service instance:

```code
# Create a join token for the Teleport Kubernetes Service to authenticate
$ TOKEN=$(tctl nodes add --roles=kube --ttl=10000h --format=json | jq -r '.[0]')
$ echo $TOKEN
```

### Install the Teleport Kubernetes Service

Install the Teleport Kubernetes Service on your Linux host or Kubernetes
cluster:

(!docs/pages/includes/install-linux.mdx!)

### Configure the Teleport Kubernetes Service

On the host where you will run the Teleport Kubernetes Service, edit your
configuration file at `/etc/teleport.yaml` to include the following:

```yaml
kubernetes_service:
  enabled: "yes"
  resources:
  - labels:
      "*": "*"
```

This configuration enables your Kubernetes Service instance to connect to any
Kubernetes clusters you register with your Teleport cluster.

<Details title="Selectively watching Kubernetes clusters">

You can configure a Kubernetes Service instance to watch for a subset of
Kubernetes clusters by naming specific labels with a configuration similar to
the following:

```yaml
resources:
- labels:
    "env": "prod"
    "region": "us-east-2"
- labels:
    "env": "test"
    "region": "us-west-1"
```

For the Kubernetes Service to register a cluster, _any_ of the items in
`resources` must match. For this to happen, _all_ of the `labels` entries within
that item must match the cluster.

For example, a cluster with `env:prod` and `region:us-east-1` would not match
the configuration above, but a cluster with `env:test` and `region:us-west-1`
would match.

When you create dynamic Kubernetes cluster resources later in this guide, you
can assign them labels to ensure that only specific Kubernetes Service instances
will watch for them.

</Details>

### Run the Teleport Kubernetes Service

On the host where you will run the Kubernetes Service, execute the following
command, depending on whether you installed Teleport using a package manager or
via a TAR archive:

<Tabs>
<TabItem label="Package Manager">

```code
sudo systemctl restart teleport
```
</TabItem>
<TabItem label="TAR archive">
```code
$ teleport start
```
</TabItem>

## Step 2/3. Authorize your user 

To enable dynamic Kubernetes cluster registration in Teleport, you will need to
authorize your user to access the Kuberntes cluster you want to register with
Teleport. You also need to authorize your user to create dynamic resources that
represent Kubernetes clusters.  

### Allow access to your Kubernetes cluster

(!docs/pages/includes/kubernetes-access/rbac.mdx!)

### Authorize your user to manage Kubernetes clusters

To manage register Kubernetes clusters with Teleport, your user will need
permissions to manage `kube_server` resources. In the previous section, you
authorized your user to view access all Kubernetes clusters registered in your
Teleport cluster. Now that you can view these clusters, create a role that
enables you to manage them.

Create a role definition called `kube-manager.yaml` with the following content: 

```yaml
kind: role
metadata:
  name: kube-manager
spec:
  allow:
    rules:
    - resources:
      - kube_server
      verbs:
      - list
      - create
      - read
      - update
      - delete
version: v5
```

## Step 3/3. Manage dynamic Kubernetes cluster resources

### Create a Kubernetes cluster resource

{/* TODO: Modify for Kubernetes*/}

Next define a database resource:

```yaml
kind: db
version: v3
metadata:
  name: example
  description: "Example database"
  labels:
    env: prod
    engine: postgres
spec:
  protocol: "postgres"
  uri: "localhost:5432"
```

To create a database resource, run:

```code
$ tctl create database.yaml
```

After the resource has been created, it will appear among the list of available
databases (in `tsh db ls` or UI) as long as at least one Database Service
instance picks it up according to its label selectors.

To update an existing database resource, run:

```code
$ tctl create -f database.yaml
```

### List Kubernetes cluster resources

{/* TODO*/}

### Delete Kubernetes cluster resources

{/* TODO: Edit the below for Kubernetes*/}

If the updated resource's labels no longer match a particular database agent, it
will unregister and stop proxying it.

To delete a database resource, run:

```code
$ tctl rm db/example
```
